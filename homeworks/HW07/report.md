# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 4 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (9, 12000)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: Числовые признаки в разных шкалах + шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (4, 8000)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: Нелинейная структура + выбросы + лишний шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (5, 15000)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: Кластеры разной плотности + фоновый шум

### 1.4 Dataset D

- Файл: `S07-hw-dataset-04.csv`
- Размер: (33, 10000)
- Признаки: числовые + 2 категориальных
- Пропуски: есть, в каждом числовом признаке около 200 пропусков
- "Подлости" датасета: Высокая размерность + 2 категориальных признака + пропуски в числовых

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: был сделан StandartScaler, SimpleImputer, OneHotEncoder для категориальных признаков
- Поиск гиперпараметров:
  - Для KMeans был диапазон подбора от 2 до 21, для метода DBSCAN перебирали eps от 1,5 до 3,5 с шагом 0,5, и сетка min samples 3,5,10
  - чем руководствовались при выборе "лучшего"
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz метрики считали по ненулевым точкам(без шума) и дополнительно фиксировали долю шума
- Визуализация: PCA(2D)

## 3. Models

Для каждого из датасетов использовали:

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- DBSCAN (`eps`, `min_samples`, доля шума)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=2
- Метрики (silhouette / DB / CH): "silhouette": 0.5216395622404242, "davies_bouldin": 0.6853295219054459,
"calinski_harabasz": 11786.95462267153
- Если был DBSCAN: шума не было и метрики полностью совпали с KMeans
- Коротко: более простое решение и кластеры довольно шарообразные, что хорошо для данной модели

### 4.2 Dataset B

- Лучший метод и параметры: KMeans, k=2
- Метрики (silhouette / DB / CH): "silhouette": 0.3068610017701601, "davies_bouldin": 1.3234721699867644,"calinski_harabasz": 3573.3933329348392
- Если был DBSCAN: Не было
- Коротко: красивый и практичный метод для данной задачи

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, k=3
- Метрики (silhouette / DB / CH): "silhouette": 0.31553248183109267, "davies_bouldin": 1.1577832240211114,"calinski_harabasz": 6957.158106946778
- Если был DBSCAN: Не было
- Коротко: возможно здесь можно лучше, но KMeans довольно хорошо справился со своей задачей

### 4.4 Dataset D

- Лучший метод и параметры: KMeans, k=7
- Метрики (silhouette / DB / CH): "silhouette": 0.36805814125837505, "davies_bouldin": 1.7108228373873862,"calinski_harabasz": 4558.868099573835
- Если был DBSCAN: шум был 48%, и соответственно метод потерял почти половину всех данных
- Коротко: был выбран KMeans, потому что нам лучше кластеризировать все точки, в то время как DBSCAN много точек отсеял

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans ломается при вытянутых кластерах (предполагает сферическую форму) и на данных с шумом - он вынужден распределять шум по кластерам
- DBSCAN выигрывает на данных с шумом, разных плотностях и формах кластеров, а также без задавания числа k
- Думаю сильнее всего на результат влияло масштабирование и плотность данных

### 5.2 Устойчивость (обязательно для одного датасета)

- Делал проверку устойчивости с помощью 5 запусков KMeans по разным seed
- Во время перебора можно было увидеть, что графики sil vs k были почти одинаковые, но результат (среднее ARI между результатами) оказался в районе 0.5, что говорит нам о том, что результаты умеренно устойчивые, но на самом краю когда можно сказать что они устойчивые 
- Вывод: умеренно устойчиво, но считаю, что возможно взятые seed были не очень удачные для инициализаций, и результат мог быть лучше

### 5.3 Интерпретация кластеров

- Способ интерпретации кластеров:
  - Для каждого кластера вычислял Z-оценки (на сколько стандартных отклонений значение отличается от среднего)
  - Вывод топ-3х наиболее отклоняющихся признаков (с наибольшим |Z| (>1.5σ))
  - Визуализация отклонений с помощью стрелок вверх или вниз, число в скобках показывает силу отклонения
- Выводы:
  - Структура данных варируется от 2 до 7 кластерных
  - В первых двух датасетах кластеры слабо отличимы (Z=+-0.5-0.7), в последнем датасете сильно лучшая
  кластеризуемость (Z=+-1.6-2.0)
  - В трех датасетах присутствует выраженная группа, которая вероятно представляет собой особые случаи или выбросы

## 6. Conclusion

- KMeans требует задания k, чувствителен к инициализации, предназначен больше для сферических кластеров
- DBSCAN находит плотные области, устойчив к шуму, но может отбросить большое количество данных
- Метрики требуют более комлексного анализа, скорее всего, для хорошей задачи одного, например, silhouette будет недостаточно
- Метрики также могут существовать без истинных меток
- Единый препроцессинг (StandardScaler) обязателен, особенно для KMeans
