# HW06 – Report

## 1. Dataset

- Выбранный датасет: `S06-hw-dataset-04.csv`
- Размер: (5, 62)
- Целевая переменная: `target`, распределение "0"-0.9508,"1"-0.0492
- Признаки: числовые

## 2. Protocol

- Разбиение: train/test, random_state=42,stratify=y,размеры выборок:
  train: (18750, 60)
  test:  (6250, 60)

Распределение классов (train):
target
0    0.950773
1    0.049227
Name: proportion, dtype: float64

Распределение классов (test):
target
0    0.95088
1    0.04912
- Подбор: CV на train, 5 фолдов, оптимизировали параметр F1-score и гиперпараметр C
- Метрики: accuracy, F1, ROC-AUC, считаю уместным использование именно этих метрик в данной задаче, потому что accuracy нужен для доли верных предсказаний, а остальные две метрики важны тем что они устойчивы к дисбалансу классов, что в нашем случае будет главным фактором

## 3. Models

- DummyClassifier (baseline)
- LogisticRegression (baseline из S05)
- DecisionTreeClassifier (подбирали: `max_depth` + `min_samples_leaf` + `ccp_alpha`)
- RandomForestClassifier (подбирали: `max_depth` + `min_samples_leaf` + `max_features`)
- HistGradientBoosting (подбирали: `learning_rate` + `max_depth` + `max_leaf_nodes`)
- StackingClassifier (с CV-логикой)

## 4. Results

- Таблица финальных метрик на test по всем моделям
accuracy	f1	roc_auc	model
5	0.98160	0.776699	0.906037	Stacking
4	0.97984	0.742857	0.904646	HistGradientBoosting
3	0.97024	0.567442	0.903547	RandomForest
1	0.96256	0.409091	0.840041	LogReg(scaled)
2	0.96848	0.588727	0.827972	DecisionTree
0	0.95088	0.000000	0.500000	Dummy(most_frequent)

- Лучшая модель вышла Stacking (по всем метрикам), так как с таким дисбалансом классов она показала лучшие результаты по метрикам, которые довольно устойчивы к дисбалансу

## 5. Analysis

- Устойчивость: при тестировании смены `random_state` (при этом оставляя stratify=y) на моделях LogReg и RandomForest, могу сделать вывод что результаты довольно стабильные, отклонения почти нет 
- Confusion matrix для лучшей модели (Stacking) показал:
TN: 5935 правильно предсказанных отрицательных
FP: всего 8 ложных срабатываний
FN: пропущено 107 положительных( главная ошибка )
TP: 200 правильно предсказанных положительных
- Интерпретация: permutation importance (top-10/15)  показал, что разница в важности 1 и последнего в top-15 признаков довольно большая, что говорит нам о том, что все дальшейшие признаки (от top-15 до top-60) скорее всего намного менее важны, чем первые в топе, поэтому могу предположить что довольно много признаков можно исключить почти без потери качества

## 6. Conclusion

- Деревья: быстро переобучаются на шумных данных, важна регуляризация и калибровка вероятностей

- Ансамбли: более устойчивы к шуму, но требуют большей настройки

- Стекинг: комбинация нескольких моделей дает хороший прирост к производительности

- Stratify + random_state: гарант воспроизводимости и одинакового распределения классов

- Интерпретируемость: permutation importance показывает важность признаков без зависимости от модели
